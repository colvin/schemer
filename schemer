#!/usr/bin/env python
#
# $Id$

"""
`schemer` composes a single stream of SQL from multiple SQL file sources using
ordering rules and performs macro replacement.

A directory structure like the following is expected:

```
  prefix/
  |-- ORDER
  |-- PROLOGUE.sql
  |-- EPILOGUE.sql
  |-- one/
  |   |-- ORDER
  |   |-- PROLOGUE.sql
  |   |-- EPILOGUE.sql
  |   |-- A.sql
  |   |-- B.sql
  |   `-- ...
  `-- two/
      |-- ORDER
      |-- PROLOGUE.sql
      |-- EPILOGUE.sql
      |-- X.sql
      |-- Y.sql
      `-- ...
```

The top-level _prefix_ directory must contain a file named `ORDER`. This file
contains an ordered list of one or more directory names, one per line,
corresponding to child directories of the prefix. This defines the order in
which directories are processed. Each child directory generally corresponds to
a schema.

Each child directory must also contain a file named `ORDER`. This file contains
an ordered list of one or more file patterns, one per line. Each pattern should
match one or more file names within that child directory, using explicit paths
rooted in that directory and/or globs. This `ORDER` file defines the order in
which files are concatenated within this directory.

If files match multiple patterns within the child directory `ORDER` file, each
file will only be processed once, and will be processed at its earliest
appearance in the order.

If a file named `PROLOGUE.sql` exists within the prefix directory, it is
processed as the first file in the sequence. If a file named `EPILOGUE.sql`
exists, it is processed as the very last file in the sequence. Similarly, each
child directory may also contain a `PROLOGUE.sql` and/or `EPILOGUE.sql` file,
which are placed at the very beginning and very end of the sequence for that
child directory.

Once the order has been determined, each file is processed for macros and
emitted to standard output (or a file if `-o FILE` is used).

Macros are identified by the pattern `MACRO{KEY}`, where `KEY` is the name of a
macro key. Macros are replaced using key/value definitions taken from a macro
file (using `-f FILE`), JSON data (using `-m JSON`), or the environment.

Macro files use a simple line-wise `key = value` syntax. No quote interpolation
is used, so any quotes in the value is considered part of the value.

Macro JSON is converted directly into a dictionary. The following will define
the macro `FOO` (which appears as `MACRO{FOO}` in the SQL files) as the value
`1`, while the macro `BAR` (`MACRO{BAR}`) will be defined as the value `bar`.

```
{"FOO":1,"BAR":"bar"}
```

If a macro is present in a SQL file and the macro key cannot be resolved, a
`KeyError` is raised and the process fails. Note that because output is
produced as files are processed an error can result in incomplete output.
"""

import os
import argparse
import glob
import json
import re
from collections import OrderedDict


class Schemer():
    def __init__(self, prefix, macro_files=None, macros=None, mode='stdout',
            output_file=None):
        """
        Construct an instance of the Schemer class.

        Arguments:
          prefix (string): the top-level directory

        Keyword Arguments:
          macro_files (list): list of file paths to macro definition files
          macros (dict): a dictionary of key-value macro definitions
          mode (string): the output data format, one of
              [`stdout`, `file`, `buffer`]
              (default: `stdout`)
          output_file (string): path to an output file, required if `mode` is
              `file`
        """

        self.prefix = prefix
        self.mode = mode
        self.output_file = output_file
        self.output_fh = None
        self.output_buffer = []
        self.order = []
        self.load_order()
        self.macros = {}
        if macro_files:
            self.load_macro_files(macro_files)
        self.add_macros(macros)

    def load_order(self):
        """
        Read the schema definition and compose the complete file order. The
        completed order is cached in the `order` attribute of the object.
        """

        with open('/'.join([self.prefix, 'ORDER']), 'r') as f:
            schema_dirs = [d.strip() for d in f.readlines()]
        for d in schema_dirs:
            with open('/'.join([self.prefix, d, 'ORDER']), 'r') as f:
                dir_globs = [e.strip() for e in f.readlines()]
            dir_files = []
            for g in dir_globs:
                for gf in sorted(glob.glob('/'.join([self.prefix, d, g]))):
                    dir_files.append(gf)
            prologue = '/'.join([self.prefix, d, 'PROLOGUE.sql'])
            if os.path.isfile(prologue):
                dir_files.insert(0, prologue)
            epilogue = '/'.join([self.prefix, d, 'EPILOGUE.sql'])
            while epilogue in dir_files:
                dir_files.remove(epilogue)
            if os.path.isfile(epilogue):
                dir_files.append('/'.join([self.prefix, d, 'EPILOGUE.sql']))
            _ = [self.order.append(e) for e in OrderedDict((i, 1) for i in dir_files).keys()]
        self.order.insert(0, '/'.join([self.prefix, 'PROLOGUE.sql']))
        self.order.append('/'.join([self.prefix, 'EPILOGUE.sql']))

    def load_macro_files(self, macro_files):
        """
        Read each file in the `macro_files` list and cache the macros they
        contain.
        """

        for mf in macro_files:
            with open(mf, 'r') as f:
                for l in f.readlines():
                    g = re.match(r'^(.*)\s+=\s+(.*)', l)
                    if g is None:
                        print('skipping: {}'.format(l))
                        continue
                    self.add_macros({g.groups()[0]: g.groups()[1]})

    def add_macros(self, macros):
        """
        Add the `macros` dictionary to the cached macros. Keys that are already
        cached by a previous call to this method or the `load_macro_files()`
        method are overwritten.
        """

        if macros:
            self.macros.update(macros)

    def get_macro_value(self, key):
        """
        Return the value of the macro with the name `key`.

        The value is taken from the cached `macros` dictionary attributes. If
        not present, `key` is requested from the environment.

        Raises:
          KeyError, if the requested key cannot be found
        """

        if key in self.macros:
            return self.macros[key]
        return os.environ[key]

    def process_line(self, line):
        """
        Replace macros found in the line of text and return the new line.
        """

        match = re.findall(r'MACRO\{(.*?)\}', line)
        if not match:
            return line
        macros = [e for e in OrderedDict((i, 1) for i in match).keys()]
        processed = line
        for m in macros:
            v = self.get_macro_value(m)
            processed = re.sub(r'MACRO{{{}}}'.format(m), v, processed)
        return processed

    def dispatch_line(self, line):
        """
        Output the line of text.

        If the `mode` is 'stdout', the line is printed to standard output. If
        the `mode` is 'file', the line is written to the file stored in the
        `output_file` attribute. If the `mode` is 'buffer', the line is
        appended to the `output_buffer` array attribute.
        """

        if self.mode == 'stdout':
            print(line)
        elif self.mode == 'file':
            print(line, file=self.output_fh)
        elif self.mode == 'buffer':
            self.output_buffer.append(line + '\n')

    def dump_order(self):
        """
        Print the file processing order to standard output.
        """

        print(json.dumps(self.order, indent=2))

    def dump_macros(self):
        """
        Print the cached macros to standard output.
        """

        print(json.dumps(self.macros, indent=2))

    def run(self):
        """
        Compose the complete schema and produce the complete output.
        """

        if self.mode == 'file':
            self.output_fh = open(self.output_file, 'w')
        for sql_file in self.order:
            with open(sql_file, 'r') as f:
                for line in f.readlines():
                    processed = self.process_line(line.rstrip())
                    self.dispatch_line(processed)
        if self.output_fh:
            self.output_fh.close()


def main():
    """
    Process command line flags and invoke the `Schemer.run()` routine.
    """

    parser = argparse.ArgumentParser(
            description='build schema files from structured components')

    parser.add_argument('-p', '--prefix', type=str, default='./schema',
            metavar='PATH', help='Path to the top-level directory of the schema definition')
    parser.add_argument('-o', '--output', type=str,
            metavar='FILE', help='Path to the output file')
    parser.add_argument('-f', '--macro-file', type=str, action='append',
            metavar='FILE', help='Path to a file containing macros')
    parser.add_argument('-m', '--macro', type=str,
            metavar='JSON', help='JSON document containing macros')

    args = parser.parse_args()

    macro_files = []
    if args.macro_file:
        macro_files = args.macro_file

    macros = None
    if args.macro:
        macros = json.loads(args.macro)

    mode = 'stdout'
    output_file = None
    if args.output:
        mode = 'file'
        output_file = args.output

    schemer = Schemer(args.prefix, macro_files=macro_files, macros=macros,
            mode=mode, output_file=output_file)
    schemer.run()

if __name__ == '__main__':
    main()
